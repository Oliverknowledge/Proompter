# ğŸ§  Proompter â€” AI Prompt Evaluation & Optimization Platform

**Built with Next.js, Supabase, Python, Opik, and LiteLLM**

---

## ğŸš€ The Problem

AI teams waste hours manually evaluating prompt quality. Without structure, iteration becomes guesswork. Metrics are inconsistent. Collaboration is messy. And scaling tests? Painful.

---

## ğŸ§© The Solution â€” Proompter

**Proompter** is a full-stack platform that **automates** prompt evaluation and **accelerates** prompt engineering workflows.

It enables teams to:
- Instantly **score prompts** across multiple metrics (e.g., hallucination, CTA strength)
- **Compare and optimize** prompt sets using A/B testing and iterative loops
- **Collaborate as a team**, track results, and make data-driven prompt decisions

This tool is built for **quick hackathons**, **startup scale**, and **production extensibility**.

---

## ğŸ› ï¸ Tech Stack

| Layer          | Tech Used                            |
| -------------- | ------------------------------------ |
| Frontend       | Next.js (App Router), React, TailwindCSS, Framer Motion, ShadCN, Three.js |
| Backend        | Next.js API Routes, Python (Opik, LiteLLM), Supabase Functions |
| Evaluation     | Python scripts with modular metric engine (hallucination, CTA, etc.) |
| Auth & DB      | Supabase Auth + Postgres (Row-level security, Team-based ACL) |
| Notifications  | Email + Telegram (optional) |
| Hosting        | Vercel (frontend) + Supabase (backend + DB) |

---

## âœ¨ Key Features

- âœ… **Automated Multi-Metric Evaluation** (relevance, hallucination, emotional tone, CTA strength)
- âš™ï¸ **Prompt Optimization Engine** (run batch A/B tests and auto-select best performers)
- ğŸ‘¥ **Team Collaboration** (invite teammates, view shared results, assign experiments)
- ğŸ“Š **Live Dashboard** (real-time metrics, history, experiments)
- ğŸ“¦ **Chunked Processing** (scale across hundreds of prompts)
- ğŸ”Œ **Extensible Python Metric System** (add custom prompt evaluators in seconds)
- ğŸ” **Secure Auth** with Email + Google OAuth

---

## ğŸ§  How It Works

1. **Sign Up & Log In**
2. **Create an Experiment**  
   Input task description and a set of prompt candidates.
3. **Automated Evaluation**  
   Prompts are sent to a Python backend via chunked requests.  
   Opik + LiteLLM score prompts across multiple dimensions.
4. **Get Results**  
   Top-performing prompts are auto-highlighted with visual scoring.
5. **Optimize & Share**  
   Run A/B tests or iterative experiments. Invite your team and share results.

---


## Code structure


proompter/
â”œâ”€â”€ app/                    # Next.js App Router structure
â”‚   â”œâ”€â”€ dashboard/          # Authenticated dashboard
â”‚   â”œâ”€â”€ experiments/        # Prompt submission + results
â”‚   â”œâ”€â”€ api/                # Backend API routes
â”‚   â”‚   â”œâ”€â”€ optimize/       # Handles batch prompt evaluation
â”‚   â”‚   â””â”€â”€ run/            # Handles one-shot evaluations
â”‚   â””â”€â”€ auth/               # Login, signup, email confirm
â”œâ”€â”€ components/             # Reusable UI (ShadCN, Framer Motion, custom)
â”œâ”€â”€ scripts/                # Python backend
â”‚   â”œâ”€â”€ optimize.py         # Core evaluation orchestrator
â”‚   â””â”€â”€ metrics/            # Add your own metrics here!
â”œâ”€â”€ lib/                    # Supabase client, chunking utils
â”œâ”€â”€ supabase/               # SQL, schema, and RLS policies
â”œâ”€â”€ public/                 # Static assets
â”œâ”€â”€ .env.example            # Example environment file
â”œâ”€â”€ README.md

## Screenshots:

![image](https://github.com/user-attachments/assets/a45c1c44-5607-4572-9b5b-a136ab2cc6a3)
![image](https://github.com/user-attachments/assets/96f5b07c-bf9b-4ee9-bc38-406e174d6611)
![image](https://github.com/user-attachments/assets/3239139f-2451-4a43-bb3b-dd9bc77a1555)



